{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928224ef-bffd-46b8-b59d-560a26fec08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import regex as re\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter, OrderedDict, namedtuple\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator, vocab\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import chain\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "# from sklearn.metrics import make_scorer\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "# from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import pycrfsuite\n",
    "from tokenizers import normalizers\n",
    "from tokenizers.normalizers import NFD, StripAccents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ebcc5-437d-4a8f-8a44-56518982d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accent_normalize(string):\n",
    "    for char in accents_dict:\n",
    "        string = re.sub(char, accents_dict[char],string)\n",
    "    return string\n",
    "\n",
    "normalizer = normalizers.Sequence([NFD(),StripAccents()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa174a-412c-4945-a6b7-85da2d6e113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = lambda x: re.sub(\"'\",\"\",normalizer.normalize_str(x))\n",
    "\n",
    "# START = \"<start>\"\n",
    "# END = \"<end>\"\n",
    "# UNK = \"<unk>\"\n",
    "# PAD = \"<pad>\"\n",
    "# BD = \"<bd>\"\n",
    "# SPECIALS = [START,END,UNK,PAD, BD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a95417-ade2-44a3-82e9-acef0a3aeb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs_codes = {\"Gitksan\": \"git\", \"Arapaho\":\"arp\", \"Lezgi\":\"lez\", \"Nyangbo\":\"nyb\", \"Tsez\":\"ddo\",\"Uspanteko\":\"usp\"}\n",
    "\n",
    "def tag_bd(seq):\n",
    "    for i, c in enumerate(seq):\n",
    "        if c == \" \":\n",
    "            seq[i] = \"<bd>\"\n",
    "    return seq\n",
    "\n",
    "# gloss_pipeline = lambda gloss: tok(tag_gloss(gloss.split(\"-\")))\n",
    "# morph_pipeline = lambda morph: list(morph)\n",
    "# word_pipeline = lambda words: list(words.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f0d13-c1d2-43c8-8024-9b844a87ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_lang_df(lang):\n",
    "    ld = {\n",
    "        \"train\": defaultdict(list),\n",
    "        \"dev\": defaultdict(list)\n",
    "    }\n",
    "        \n",
    "    path = f\"data/{lang}/\"\n",
    "    train_fn = f\"{langs_codes[lang]}-train-track2-uncovered\"\n",
    "    dev_fn = f\"{langs_codes[lang]}-dev-track2-uncovered\"\n",
    "\n",
    "    for fp in [train_fn, dev_fn]:\n",
    "        data_type = fp.split(\"-\")[1]\n",
    "        with open(path + fp, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                \n",
    "\n",
    "                if line.startswith(\"\\\\t\"):\n",
    "                    ld[data_type][\"transcription\"].append(normalize(line.lstrip(\"\\\\t \").rstrip(\"\\n\")))\n",
    "                if line.startswith(\"\\g\"):\n",
    "                    ld[data_type][\"gloss\"].append(normalize(line.lstrip(\"\\\\g \").rstrip(\"\\n\")))\n",
    "                if line.startswith(\"\\m\"):\n",
    "                    ld[data_type][\"morphemes\"].append(normalize(line.lstrip(\"\\\\m \").rstrip(\"\\n\")))\n",
    "\n",
    "                if line.startswith(\"\\l\"):\n",
    "                    ld[data_type][\"translation\"].append(normalize(line.lstrip(\"\\\\l \").rstrip(\"\\n\")))\n",
    "    \n",
    "    train_df = pd.DataFrame.from_dict(ld[\"train\"])\n",
    "    dev_df = pd.DataFrame.from_dict(ld[\"dev\"])\n",
    "    \n",
    "    return train_df,dev_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d5f7ba-b5fd-4fab-9f6f-ce6d710e48cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def yield_input(data):\n",
    "    #data = data.loc[:, \"input\"].apply(lambda x: list(x)) + data.loc[:, \"msd\"].apply(lambda x: x.split(\";\")).apply(lambda x: [\"FEAT=\"+ l for l in x])\n",
    "    for ex in data:#.iloc[:, 0].apply(lambda x: list(x)) + data.iloc[:, 2].apply(lambda x: x.split(\";\")).apply(lambda x: [\"FEAT=\"+ l for l in x]):\n",
    "        \n",
    "\n",
    "        #if ex == \"msd\":\n",
    "            #data[ex].apply(lambda x: x.split(\";\")).apply(lambda x: [\"FEAT=\"+ l for l in x])\n",
    "        yield [\"<start>\"] +tag_bd(list(ex.transcription)) + [\"<end>\"]\n",
    "\n",
    "    \n",
    "def yield_output(data):\n",
    "    for ex in data:#.iloc[:, 1].apply(lambda x:list(x)):\n",
    "        yield [\"<start>\"] + list(ex.morphemes) + [\"<end>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93864477-6056-41df-b962-be0d0075065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UDDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.iloc = data.iloc\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.iloc[index]   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed22d7a-fb8c-4d10-ad64-893b723cba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_vocab(lang,batch_size):\n",
    "\n",
    "    train_df, dev_df = get_lang_df(lang)\n",
    "    \n",
    "    train = UDDataset(train_df)\n",
    "    dev = UDDataset(dev_df)\n",
    "    \n",
    "    vocab = build_vocab_from_iterator(chain(yield_input(train), yield_output(train)), specials=SPECIALS)\n",
    "    vocab.set_default_index(vocab[UNK]) \n",
    "    \n",
    "    sequence_transform = lambda s:[vocab[c] for c in s]\n",
    "    \n",
    "    def collate_batch(batch):\n",
    "            input, output = [], []\n",
    "            for orth, morph in zip(yield_input(batch), yield_output(batch)):\n",
    "                input_tensor = torch.tensor(sequence_transform(orth), dtype=torch.long)\n",
    "                output_tensor = torch.tensor(sequence_transform(morph), dtype=torch.long)\n",
    "                input.append(input_tensor)\n",
    "                output.append(output_tensor)\n",
    "            \n",
    "            return pad_sequence(input, batch_first=False, padding_value=vocab[PAD]), pad_sequence(output, batch_first=False, padding_value=vocab[PAD])\n",
    "        \n",
    "    train_iter = DataLoader(train, batch_size=1, shuffle=True, collate_fn=collate_batch)\n",
    "    dev_iter = DataLoader(dev, batch_size=1, shuffle=True, collate_fn=collate_batch)\n",
    "    \n",
    "    return train,dev_iter,vocab\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
